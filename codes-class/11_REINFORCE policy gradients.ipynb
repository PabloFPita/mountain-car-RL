{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310cc18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc51fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To get smooth animations\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2a35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  Using gym\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ee5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  Example Cart_Pole\n",
    "\n",
    "# It is a very simple environment composed of a cart that can move left or right, and pole placed vertically on top of it. \n",
    "# The agent must move the cart left or right to keep the pole upright.\n",
    "\n",
    "# selecting the gym environment\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81d53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the environment with reset\n",
    "#env.seed(42)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac716f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 600, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this example we will set mode=\"rgb_array\" to get an image of the environment as a NumPy array:\n",
    "img = env.render()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0936c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_environment(env, figsize=(5,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc42e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_environment(env)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ea12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################   USING A NEURAL NETWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9cc7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6eb0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################  POLICY GRADIENTS  ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train this neural network we will need to define the target probabilities y. If an action is good we should increase \n",
    "# its probability, and conversely if it is bad we should reduce it. But how do we know whether an action is good or bad? \n",
    "# The problem is that most actions have delayed effects, so when you win or lose points in an episode, it is not clear \n",
    "# which actions contributed to this result: was it just the last action? Or the last 10? Or just one action 50 steps earlier? \n",
    "# This is called the credit assignment problem.\n",
    "\n",
    "# The Policy Gradients algorithm tackles this problem by first playing multiple episodes, then making the actions \n",
    "# in good episodes slightly more likely, while actions in bad episodes are made slightly less likely. \n",
    "# First we play, then we go back and think about what we did.\n",
    "\n",
    "# Let's start by creating a function to play a single step using the model. We will also pretend for now that whatever \n",
    "# action it takes is the right one, so we can compute the loss and its gradients \n",
    "# (we will just save these gradients for now, and modify them later depending on how good or bad the action turned out to be):\n",
    "\n",
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #print(\"obs\", obs)\n",
    "        #left_proba = model(obs[0])              # output of the model after obs is used as input\n",
    "        #left_proba = model(obs[0].reshape(-1, 1,4))              # output of the model after obs is used as input\n",
    "        left_proba = model(obs.reshape(-1, 1,4))              # output of the model after obs is used as input\n",
    "        #print(\"left_proba\", left_proba)\n",
    "        action = (tf.random.uniform([1, 1]) > left_proba)  # Action True or False\n",
    "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32)\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, reward, done, tr,info = env.step(int(action[0, 0].numpy()))\n",
    "    return obs, reward, done, grads\n",
    "\n",
    "# If left_proba is high, then action will most likely be False (since a random number uniformally sampled between 0 and 1 \n",
    "# will probably not be greater than left_proba). And False means 0 when you cast it to a number, so y_target would be equal \n",
    "# to 1 - 0 = 1. In other words, we set the target to 1, meaning we pretend that the probability of going left should have been \n",
    "# 100% (so we took the right action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f1aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create another function that will rely on the play_one_step() function to play multiple episodes,\n",
    "# returning all the rewards and gradients, for each episode and each step:\n",
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        obs = env.reset()\n",
    "        obs=obs[0]\n",
    "        for step in range(n_max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd467fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Policy Gradients algorithm uses the model to play the episode several times (e.g., 10 times), then it goes back and \n",
    "# looks at all the rewards, discounts them and normalizes them. So let's create couple functions for that: the first will \n",
    "# compute discounted rewards; the second will normalize the discounted rewards across many episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d4676c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1):\n",
    "        discounted[step] += discounted[step + 1] * discount_rate\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate)\n",
    "                              for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std\n",
    "            for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5011cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22, -40, -50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of use discounts\n",
    "discount_rewards([10, 0, -50], discount_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e0186a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say there were 3 actions, and after each action there was a reward: first 10, then 0, then -50. If we use a discount factor \n",
    "# of 80%, then the 3rd action will get -50 (full credit for the last reward), but the 2nd action will only get -40 \n",
    "# (80% credit for the last reward), and the 1st action will get 80% of -40 (-32) plus full credit for the first reward (+10), \n",
    "# which leads to a discounted reward of -22:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c3e79ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.28435071, -0.86597718, -1.18910299]),\n",
       " array([1.26665318, 1.0727777 ])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To normalize all discounted rewards across all episodes, we compute the mean and standard deviation of all the discounted \n",
    "# rewards, and we subtract the mean from each discounted reward, and divide by the standard deviation:\n",
    "discount_and_normalize_rewards([[10, 0, -50], [10, 20]], discount_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3275f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of use\n",
    "\n",
    "# We will run 150 training iterations, playing 10 episodes per iteration, and each episode\n",
    "# will last at most 200 steps. We will use a discount factor of 0.95:\n",
    "\n",
    "n_iterations = 150\n",
    "n_episodes_per_update = 10\n",
    "n_max_steps = 200\n",
    "discount_rate = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ece4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need an optimizer and the loss function. A regular Adam optimizer with\n",
    "# learning rate 0.01, and we will use the binary cross-entropy loss function\n",
    "# because we are training a binary classifier (there are two possible actions: left or right):\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3bf30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\masanz\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\common\\global_state.py:73: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NN model \n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(5, activation=\"elu\", input_shape=(1,4)),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9325c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 149, mean rewards: 188.1"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "#env.seed(42);\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    all_rewards, all_grads = play_multiple_episodes(env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
    "    total_rewards = sum(map(sum, all_rewards))                     \n",
    "    print(\"\\rIteration: {}, mean rewards: {:.1f}\".format(          \n",
    "        iteration, total_rewards / n_episodes_per_update), end=\"\") \n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards,\n",
    "                                                       discount_rate)\n",
    "    all_mean_grads = []\n",
    "    for var_index in range(len(model.trainable_variables)):\n",
    "        mean_grads = tf.reduce_mean(\n",
    "            [final_reward * all_grads[episode_index][step][var_index]\n",
    "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
    "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb834d9-51d4-4e38-a7a0-30bd2c225d0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e932db",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "• At each training iteration, this loop calls the play_multiple_episodes() function,\n",
    "which plays the game 10 times and returns all the rewards and gradients for\n",
    "every episode and step.\n",
    "• Then we call the discount_and_normalize_rewards() to compute each action’s\n",
    "normalized advantage (which in the code we call the final_reward). This provides\n",
    "a measure of how good or bad each action actually was, in hindsight.\n",
    "• Next, we go through each trainable variable, and for each of them we compute\n",
    "the weighted mean of the gradients for that variable over all episodes and all\n",
    "steps, weighted by the final_reward.\n",
    "• Finally, we apply these mean gradients using the optimizer: the model’s trainable\n",
    "variables will be tweaked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fedfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d726ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_policy_net(model, n_max_steps=200, seed=42):\n",
    "    frames = []\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "    #env.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    for step in range(n_max_steps):\n",
    "        frames.append(env.render())\n",
    "        left_proba = model.predict(obs.reshape(-1, 1,4))\n",
    "        #left_proba = model(obs.reshape(-1, 1,4)) \n",
    "        action = int(np.random.rand() > left_proba)\n",
    "        obs, reward, done, tr, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db72ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b756512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m frames \u001b[38;5;241m=\u001b[39m render_policy_net(model)\n\u001b[1;32m----> 2\u001b[0m plot_animation(frames)\n",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m, in \u001b[0;36mplot_animation\u001b[1;34m(frames, repeat, interval)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_animation\u001b[39m(frames, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m):\n\u001b[0;32m      6\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m----> 7\u001b[0m     patch \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(frames[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     anim \u001b[38;5;241m=\u001b[39m animation\u001b[38;5;241m.\u001b[39mFuncAnimation(\n\u001b[0;32m     10\u001b[0m         fig, update_scene, fargs\u001b[38;5;241m=\u001b[39m(frames, patch),\n\u001b[0;32m     11\u001b[0m         frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(frames), repeat\u001b[38;5;241m=\u001b[39mrepeat, interval\u001b[38;5;241m=\u001b[39minterval)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:3346\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   3325\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   3326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   3327\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[1;32m-> 3346\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   3347\u001b[0m         X,\n\u001b[0;32m   3348\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[0;32m   3349\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   3350\u001b[0m         aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   3351\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   3352\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m   3353\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   3354\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[0;32m   3355\u001b[0m         origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   3356\u001b[0m         extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   3357\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   3358\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   3359\u001b[0m         filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[0;32m   3360\u001b[0m         resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   3361\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   3362\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3363\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3364\u001b[0m     )\n\u001b[0;32m   3365\u001b[0m     sci(__ret)\n\u001b[0;32m   3366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5751\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5751\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[0;32m   5752\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5754\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_image_array(A)\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:688\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    686\u001b[0m A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = render_policy_net(model)\n",
    "plot_animation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a9760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
